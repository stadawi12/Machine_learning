We will be using machine learning techniques to train a
computer to recognise if there are cats in the images that
we provide it.  The images will be $64 \times 64 \times 3$
large as they are in the RGB format.  We have 209 training
images that we will use to train the computer with.  Each
training image can be represented as a vector of size
$12,288$.

\begin{equation}
    x^{(i)} = 
    \begin{pmatrix}
        q_1^{(i)} \\
        q_2^{(i)} \\
        \vdots \\
        q_{12288}^{(i)}
    \end{pmatrix}.
\end{equation}

The set of all images can then be represented as a matrix

\begin{equation}
    X = 
    \begin{pmatrix}
        \vdots & \vdots & & \vdots \\
        x^{(1)} & x^{(2)} & \dots & x^{(209)} \\
        \vdots & \vdots & & \vdots
    \end{pmatrix}.
\end{equation}

We will be using Logistic Regression to train our computer.
In a single training image we have $12,288$ parameters that
can vary, these are all the pixels that make up the $64
\times 64 \times 3$ image.

Each image is labeled either as 'cat' or 'non-cat'. Logistic
regression works by assigning a single number to each image
by calculating $y^{(i)} = w^T x^{(i)} + b$ and sending it
through an activation function $\sigma(y^{(i)}) = \frac{1}{1
+ \exp(-y^{(i)}) }$, this function will output a number
between $0$ and $1$, given that the weights $w$ and the bias
$b$ are "correctly" chosen, we should get $1$ whenever we
pass through a 'cat' image and we should get a $0$ for a
'non-cat' image. 

\begin{equation}
    w = 
    \begin{pmatrix}
        w_1 \\
        w_2 \\
        \vdots \\
        w_{12288}
    \end{pmatrix}.
\end{equation}  

Of course, this method is not exact so the best we can hope
for is that the sigmoid function $\sigma(y^{(i)})$ will give
us an answer close to $1$ or close to $0$ for either a 'cat'
or 'non-cat' image, respectively.

When the algorithm starts, we choose the weights and biases
at random so the computer will give us random outcomes and
will not be helpful at all at determining whether an image
does or does not contain a cat in it.

This is where the 'learning' part comes in, we start with a
random assumption of weights and the bias and then we pass
all the training data (training images) through the sigmoid
function and for each image we obtain a number that is the
difference from the truth.

So, for example, if we have a 'cat' image this means we
should be getting a $1$ from the sigmoid function, but let's
say we get $\sigma(y^{(i)})=0.31$ so the difference from the
true result is $0.69$, this number is called a
\textit{loss}. 

Preferably we would like this number to always be $0$ for
each image but as we have $209$ training images we can
imagine that we will always have some losses in our
algorithm. Having $209$ training images, we can calculate
$209$ losses, one for each image.

Now you can imagine that what we are looking for is that all
of these losses to be as small as possible, therefore we
invent a quantity called the \textit{cost} $(J)$ which we
will define as

\begin{equation}
    J = \frac{1}{m} \sum losses
\end{equation}
where $m$ is the number of training examples, in our case $m=209$.

Now we get to the minimisation part of the algorithm. Given
our weight and bias we have calculated a single number $J$,
and we can imagine that in the first run of the code with
random weights and biases, this number will most likely be
relatively large.  Therefore, it is now time to update the
weights and bias so that on the next run $J$ will be
smaller. So some weights might need to be lowered, some
might need to be turned up, doing this by hand is obviously
impossible (or very tedious at the least).  So we need a
method that tells us how to alter each weight and the bias
in order to reduce the cost function. The goal is for each
run we want to get a smaller cost function, the number of
runs (or iterations) depends on us, normally we stop when
the cost function doesn't change much. Now, I understand
that I am being quite vague with my terminology but we will
get more concrete with definitions later, right now I am
just rying to present the big picture, later we will get
into the nitty-gritty details.

This procedure of trying to obtain the smallest possible
cost function is called minimisation. There are multiple
methods to minimise the cost function, the one that we will
go with will be minimisation via gradient-descent.

Gradient-descent is a straight forward method of obtaining a
minimum of a function. We can imagine that the function $J$
lives in some highly dimensional space and it is very
wiggly, if we specify all the weights and the bias we will
find ourselves somewhere in that space with a value
$J(w,b)$, standing at that point we would surely know where
is up and where is down, or how to get to the bottom of the
'valley' of this function, we would just follow the path of
steepest descent and slowly make our way to the bottom of
that function.  This is what gradient descent is about. We
start at some position $J(w_0,b_0)$ and we try to make our
way to $J(w_{min}, b_{min})$ where $w_{min}$ and $b_{min}$
is the position of the lowest point of the $J(w,b)$
function.

The disadvantage of this method is that if there exist
multiple valleys in the $J$ function, gradient descent will
only be sensitive to the local valley that it will be placed
in, because it doesn't seek the lowest point of the function
but rather the lowest local point of the function. This
problem can be managed by choosing multiple starting points
for the gradient descent and each of them reporting the
lowest point that they got to, and then we choose the
'explorer' which has found the lowest laying valley.

To use gradient descent we need to calculate the gradient of
the $J$ function with respect to each weight and the bias,
so we need to calculate $\frac{\partial J}{\partial
w^{(i)}}$ and $\frac{\partial J }{\partial b}$. Using those
gradients we can determine which direction we want to move
the weight or the bias.  For example if we find that
$\frac{\partial J}{ \partial w^{(i)}}$ is positive, that
means we want to move in the opposite direction such that
\begin{equation}\label{eq:update} w^{(i)}_{new} =
    w^{(i)}_{old} - \frac{\partial J}{\partial w^{(i)}}
\end{equation} but to make this equation slightly more
reasonable we will determine a learning rate $\alpha$ which
will be some small positive number that will enter Eq.
(\ref{eq:update}) as \begin{equation} w^{(i)}_{new} =
w^{(i)}_{old} - \alpha \frac{\partial J}{\partial w^{(i)}}.
\end{equation} This serves as a bottleneck for how fast the
weights and bias get updated.  For example, we do not want
the parameters to overshoot the valley.  $\alpha$ determines
the step size of the gradient descent. We call that the
learning rate, as it determines how fast the computer learns
or how many iterations it takes the computer to reach the
minimum point of the function, this should not be too quick
and not too slow, so a good learning rate is important but
the choice is more or less arbitrary, usual learning rates
are around $0.1$ or $0.01$ but it varies based on different
problems.

So far, we have a procedure for updating the parameters
using gradient descent where we calculate the gradient of
the point we are standing at and then depending whether that
gradient is positive or negative we move accordingly with a
step size determined by the learning rate.

Now after updating each parameter, we recalculate the cost
function $J(w,b)$, we should find that now it is smaller
than it was before and we repeat the process. After some
time we will find that we will reach a plateau and the cost
function will no longer be changing, we have reached a
minimum, this can happen after $1,000$ or $10,000$
iterations, but we will surely get there.

Having reached the minimum we now have our weight and bias
set as best as we can given our training data. We should
save the values of those weights and bias and use them to
test how well we have managed to train our computer to
recognise images containing cats in them. We could now pass
an image the computer has never seen before through the $y =
w^T x + b$ function and then through the sigmoid function,
and we would obtain a number, let's say there was a cat in
that picture and our computer outputs a number of $\sigma(y)
= 0.85$ we could treat that as the computer is pretty
confident that there is a cat in this image and we would
round this number to $1$, saying there is a cat in this
picture, of course the computer can be wrong but this is how
we determine what the computer thinks, values above $0.5$
are treated as though the computer believes there is a cat
and numbers below mean the computer thinks there is no cat
in the image.

This was an introduction into the problem and hopefully I
have not used any concepts that are foreign. I have been
quite vague in this introduction with certain aspects in
order to not confuse the reasoning by adding unnecessary
complications. This introduction is a very raw and basic
idea of how Logistic Regression can be used to solve a
simple machine learning problem. We will now go into more
detail in order to prepare one for coding their own machine
learning program to distinguish cat images from non-cat
images.t

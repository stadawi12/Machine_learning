The loss function which we have mentioned previously was a very simplistic
function described as the difference between the true value and the one
given by the sigmoid function.

\begin{equation}
    \mathscr{L}_{\text{simple}} = |y_{true}^{(i)} - \sigma(y^{(i)}) |.
\end{equation}
The above is a simplistic function and not the one commonly used.

The one that we will use will be slightly more complicated but 
the idea remains, it will still serve as a test for the difference
between true value and a predicted one.

\begin{equation}
    \mathscr{L}^{(i)} = -y_{true}^{(i)} \log (a^{(i)}) - (1 - y_{true}^{(i)})
    \log(1 - a^{(i)}),
\end{equation}
where $a^{(i)} \equiv \sigma(y^{(i)})$.

Now the cost function reads,
\begin{equation}
    J = \frac{1}{m} \sum_{i=1}^m \mathscr{L}^{(i)},
\end{equation}
We need to be able to calculate the derivative of the cost function
for the purposes of updating our parameters.
It turns out the solution is quite simple,
\begin{align}
    \frac{\partial J}{\partial w} &= 
    \frac{1}{m}  X(A - Y)^T, \\
    \frac{\partial J}{\partial b} &=
    \frac{1}{m}
    \sum_{i=1}^m (a^{(i)} - y^{(i)}_{\text{t}}),
\end{align}
where 
$A = (a^{(1)}, a^{(2)},...,a^{(m)})$
and
$Y = (y^{(1)}_{\text{t}}, y^{(2)}_{\text{t}},..., y^{(m)}_{\text{t}})$
, with 't' standing
for true.
